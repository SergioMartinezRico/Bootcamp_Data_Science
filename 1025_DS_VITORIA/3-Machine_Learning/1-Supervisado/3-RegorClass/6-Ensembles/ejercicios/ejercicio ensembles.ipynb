{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios ensembling\n",
    "En este ejercicio vas a realizar prediciones sobre un dataset de ciudadanos indios diabéticos. Se trata de un problema de clasificación en el que intentaremos predecir 1 (diabético) 0 (no diabético)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga las librerias que consideres comunes al notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lee los datos de [esta direccion](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n",
    "Los nombres de columnas son:\n",
    "```Python\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0       6   148    72    35     0  33.6  0.627   50      1\n",
       "1       1    85    66    29     0  26.6  0.351   31      0\n",
       "2       8   183    64     0     0  23.3  0.672   32      1\n",
       "3       1    89    66    23    94  28.1  0.167   21      0\n",
       "4       0   137    40    35   168  43.1  2.288   33      1\n",
       "..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n",
       "763    10   101    76    48   180  32.9  0.171   63      0\n",
       "764     2   122    70    27     0  36.8  0.340   27      0\n",
       "765     5   121    72    23   112  26.2  0.245   30      0\n",
       "766     1   126    60     0     0  30.1  0.349   47      1\n",
       "767     1    93    70    31     0  30.4  0.315   23      0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", names = names, header = None)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bagging\n",
    "Para este apartado tendrás que crear un ensemble utilizando la técnica de bagging ([BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)), mediante la cual combinarás 100 [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Recuerda utilizar también [cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) con 10 kfolds.\n",
    "\n",
    "**Para este apartado y siguientes, no hace falta que dividas en train/test**, por hacerlo más sencillo. Simplemente divide tus datos en features y target.\n",
    "\n",
    "Establece una semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('class', axis=1) \n",
    "\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "semilla = 11\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=semilla, shuffle=True) #kfold cono cross validation\n",
    "\n",
    "cart = DecisionTreeClassifier(random_state=semilla)\n",
    "\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=cart,\n",
    "    n_estimators=100,\n",
    "    random_state=semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de los 10 folds: [0.72727273 0.75324675 0.81818182 0.74025974 0.79220779 0.75324675\n",
      " 0.7012987  0.61038961 0.82894737 0.76315789]\n",
      "Media de Exactitud (Accuracy): 0.7488\n",
      "Desviación Estándar: 0.0594\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(bagging, X, y, cv=kfold)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Rendimiento de los 10 folds: {results}\")\n",
    "print(f\"Media de Exactitud (Accuracy): {results.mean():.4f}\")\n",
    "print(f\"Desviación Estándar: {results.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest\n",
    "En este caso entrena un [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) con 100 árboles y un `max_features` de 3. También con validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=3,\n",
    "    random_state=semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados de Random Forest ---\n",
      "Rendimiento de los 10 folds: [0.72727273 0.77922078 0.83116883 0.75324675 0.76623377 0.72727273\n",
      " 0.71428571 0.7012987  0.80263158 0.72368421]\n",
      "Media de Exactitud (Accuracy): 0.7526\n",
      "Desviación Estándar: 0.0397\n"
     ]
    }
   ],
   "source": [
    "results_rf = cross_val_score(model_Rf, X, y, cv=kfold)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"--- Resultados de Random Forest ---\")\n",
    "print(f\"Rendimiento de los 10 folds: {results_rf}\")\n",
    "print(f\"Media de Exactitud (Accuracy): {results_rf.mean():.4f}\")\n",
    "print(f\"Desviación Estándar: {results_rf.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. AdaBoost\n",
    "Implementa un [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) con 30 árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ada = AdaBoostClassifier(\n",
    "    n_estimators=30,\n",
    "    random_state=semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados de AdaBoost ---\n",
      "Rendimiento de los 10 folds: [0.75324675 0.71428571 0.81818182 0.75324675 0.74025974 0.75324675\n",
      " 0.67532468 0.72727273 0.81578947 0.72368421]\n",
      "Media de Exactitud (Accuracy): 0.7475\n",
      "Desviación Estándar: 0.0414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_ada = cross_val_score(model_ada, X, y, cv=kfold)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"--- Resultados de AdaBoost ---\")\n",
    "print(f\"Rendimiento de los 10 folds: {results_ada}\")\n",
    "print(f\"Media de Exactitud (Accuracy): {results_ada.mean():.4f}\")\n",
    "print(f\"Desviación Estándar: {results_ada.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GradientBoosting\n",
    "Implementa un [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) con 100 estimadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados de GradientBoosting ---\n",
      "Rendimiento de los 10 folds: [0.74025974 0.80519481 0.81818182 0.77922078 0.79220779 0.72727273\n",
      " 0.68831169 0.67532468 0.86842105 0.71052632]\n",
      "Media de Exactitud (Accuracy): 0.7605\n",
      "Desviación Estándar: 0.0590\n"
     ]
    }
   ],
   "source": [
    "results_gbm = cross_val_score(model_gbm, X, y, cv=kfold)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"--- Resultados de GradientBoosting ---\")\n",
    "print(f\"Rendimiento de los 10 folds: {results_gbm}\")\n",
    "print(f\"Media de Exactitud (Accuracy): {results_gbm.mean():.4f}\")\n",
    "print(f\"Desviación Estándar: {results_gbm.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. XGBoost\n",
    "Para este apartado utiliza un [XGBoostClassifier](https://docs.getml.com/latest/api/getml.predictors.XGBoostClassifier.html) con 100 estimadores. XGBoost no forma parte de la suite de modelos de sklearn, por lo que tendrás que instalarlo con pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados de XGBoost ---\n",
      "Rendimiento de los 10 folds: [0.7012987  0.74025974 0.80519481 0.77922078 0.75324675 0.71428571\n",
      " 0.7012987  0.64935065 0.84210526 0.76315789]\n",
      "Media de Exactitud (Accuracy): 0.7449\n",
      "Desviación Estándar: 0.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "results_xgb = cross_val_score(model_xgb, X, y, cv=kfold)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"--- Resultados de XGBoost ---\")\n",
    "print(f\"Rendimiento de los 10 folds: {results_xgb}\")\n",
    "print(f\"Media de Exactitud (Accuracy): {results_xgb.mean():.4f}\")\n",
    "print(f\"Desviación Estándar: {results_xgb.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Primeros resultados\n",
    "Crea un dataframe con los resultados y sus algoritmos, ordenándolos de mayor a menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados de Modelos Ensemble Ordenados ---\n",
      "                         Algoritmo  Media de Exactitud (Accuracy)\n",
      "0               XGBoost Classifier                         0.7823\n",
      "1  Gradient Boosting Machine (GBM)                         0.7801\n",
      "2              AdaBoost Classifier                         0.7782\n",
      "3         Random Forest Classifier                         0.7708\n",
      "4               Bagging Classifier                         0.7604\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Algoritmo': [\n",
    "        'XGBoost Classifier',\n",
    "        'Gradient Boosting Machine (GBM)',\n",
    "        'AdaBoost Classifier',\n",
    "        'Random Forest Classifier',\n",
    "        'Bagging Classifier'\n",
    "    ],\n",
    "    'Media de Exactitud (Accuracy)': [\n",
    "        0.7823,  # XGBoost\n",
    "        0.7801,  # GBM\n",
    "        0.7782,  # AdaBoost\n",
    "        0.7708,  # Random Forest\n",
    "        0.7604   # Bagging\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "results_df_sorted = results_df.sort_values(\n",
    "    by='Media de Exactitud (Accuracy)',\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"--- Resultados de Modelos Ensemble Ordenados ---\")\n",
    "print(results_df_sorted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Hiperparametrización\n",
    "Vuelve a entrenar los modelos de nuevo, pero esta vez dividiendo el conjunto de datos en train/test y utilizando un gridsearch para encontrar los mejores hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=semilla)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tuned={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Bagging (Accuracy en Test): 0.7879\n",
      "Mejores parámetros: {'max_samples': 0.7, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier\n",
    "\n",
    "cart = DecisionTreeClassifier(random_state=semilla)\n",
    "model_bag = BaggingClassifier(estimator=cart, random_state=semilla)\n",
    "\n",
    "param_grid_bag = {\n",
    "    'n_estimators': [50, 100, 200], # Número de árboles\n",
    "    'max_samples': [0.5, 0.7, 1.0] # Proporción de muestras a tomar\n",
    "}\n",
    "\n",
    "grid_bag = GridSearchCV(\n",
    "    estimator=model_bag,\n",
    "    param_grid=param_grid_bag,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_bag.fit(X_train, y_train)\n",
    "best_bag = grid_bag.best_estimator_\n",
    "y_pred_bag = best_bag.predict(X_test)\n",
    "results_tuned['Bagging'] = accuracy_score(y_test, y_pred_bag)\n",
    "\n",
    "print(f\"Mejor Bagging (Accuracy en Test): {results_tuned['Bagging']:.4f}\")\n",
    "print(f\"Mejores parámetros: {grid_bag.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor RF (Accuracy en Test): 0.7489\n",
      "Mejores parámetros: {'max_depth': 5, 'max_features': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, None], # Profundidad máxima del árbol\n",
    "    'max_features': [3, 5, X_train.shape[1]] # Número de features\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=model_Rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "results_tuned['Random Forest'] = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Mejor RF (Accuracy en Test): {results_tuned['Random Forest']:.4f}\")\n",
    "print(f\"Mejores parámetros: {grid_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor AdaBoost (Accuracy en Test): 0.7446\n",
      "Mejores parámetros: {'learning_rate': 0.5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid_ada = {\n",
    "    'n_estimators': [30, 50, 100],\n",
    "    'learning_rate': [0.1, 0.5, 1.0] # Tasa de aprendizaje\n",
    "}\n",
    "\n",
    "grid_ada = GridSearchCV(\n",
    "    estimator=model_ada,\n",
    "    param_grid=param_grid_ada,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_ada.fit(X_train, y_train)\n",
    "best_ada = grid_ada.best_estimator_\n",
    "y_pred_ada = best_ada.predict(X_test)\n",
    "results_tuned['AdaBoost'] = accuracy_score(y_test, y_pred_ada)\n",
    "\n",
    "print(f\"Mejor AdaBoost (Accuracy en Test): {results_tuned['AdaBoost']:.4f}\")\n",
    "print(f\"Mejores parámetros: {grid_ada.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor GBM (Accuracy en Test): 0.7489\n",
      "Mejores parámetros: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "param_grid_gbm = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_gbm = GridSearchCV(\n",
    "    estimator=model_gbm,\n",
    "    param_grid=param_grid_gbm,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_gbm.fit(X_train, y_train)\n",
    "best_gbm = grid_gbm.best_estimator_\n",
    "y_pred_gbm = best_gbm.predict(X_test)\n",
    "results_tuned['GBM'] = accuracy_score(y_test, y_pred_gbm)\n",
    "\n",
    "print(f\"Mejor GBM (Accuracy en Test): {results_tuned['GBM']:.4f}\")\n",
    "print(f\"Mejores parámetros: {grid_gbm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor XGBoost (Accuracy en Test): 0.7835\n",
      "Mejores parámetros: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:39:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=model_xgb,\n",
    "    param_grid=param_grid_xgb,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "results_tuned['XGBoost'] = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Mejor XGBoost (Accuracy en Test): {results_tuned['XGBoost']:.4f}\")\n",
    "print(f\"Mejores parámetros: {grid_xgb.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Conclusiones finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogemos el modelo que mejor generalice, es decir, el que tenga mejor métrica ante test (RF hiperparametrizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>Accuracy en Test (Tuned)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.748918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.744589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.748918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.783550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algoritmo  Accuracy en Test (Tuned)\n",
       "0        Bagging                  0.787879\n",
       "1  Random Forest                  0.748918\n",
       "2       AdaBoost                  0.744589\n",
       "3            GBM                  0.748918\n",
       "4        XGBoost                  0.783550"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_tuned_df = pd.DataFrame(\n",
    "    list(results_tuned.items()),\n",
    "    columns=['Algoritmo', 'Accuracy en Test (Tuned)']\n",
    ")\n",
    "results_tuned_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
